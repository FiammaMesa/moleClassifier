{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os, shutil, glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare directories with images on classified folders\n",
    "\n",
    "images = []\n",
    "df = pd.read_csv('HAM10000_metadata.csv')\n",
    "df_dx = df.dx.unique()\n",
    "\n",
    "if os.path.exists('data_images'):\n",
    "    shutil.rmtree('data_images') \n",
    "\n",
    "os.mkdir('data_images')\n",
    "\n",
    "    \n",
    "for dx in df_dx:\n",
    "    dirName = 'data_images/' + dx\n",
    "    if not os.path.exists(dirName):\n",
    "        os.mkdir(dirName)\n",
    "        \n",
    "images_1 = [f for f in listdir('HAM10000_images_part_1') if isfile(join('HAM10000_images_part_1', f))]\n",
    "images_2 = [f for f in listdir('HAM10000_images_part_2') if isfile(join('HAM10000_images_part_2', f))]\n",
    "\n",
    "for f in images_1:\n",
    "    dx_dir = 'data_images/' + df.loc[df['image_id'] == os.path.splitext(f)[0], 'dx'].values.item()\n",
    "    shutil.copy('HAM10000_images_part_1/' + f, dx_dir)\n",
    "    images.append(dx_dir + '/' + f)\n",
    "    \n",
    "for f in images_2:\n",
    "    dx_dir = 'data_images/' + df.loc[df['image_id'] == os.path.splitext(f)[0], 'dx'].values.item()\n",
    "    shutil.copy('HAM10000_images_part_2/' + f, dx_dir)\n",
    "    images.append(dx_dir + '/' + f)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate more samples by mirroring images\n",
    "\n",
    "#import cv2, csv\n",
    "\n",
    "#last_sample_name = 34321\n",
    "\n",
    "#if os.path.exists('HAM10000_metadata_with_more_samples.csv'):\n",
    "#    os.remove('HAM10000_metadata_with_more_samples.csv')\n",
    "    \n",
    "#shutil.copy('HAM10000_metadata.csv', 'HAM10000_metadata_with_more_samples.csv')\n",
    "\n",
    "#def flipImage(img, image_path, direction, last_sample_name, csv_line):\n",
    "#    flipped = cv2.flip(img, direction)\n",
    "#    cv2.imwrite(image_path, flipped)\n",
    "#    writeLinesInCsv('HAM10000_metadata_with_more_samples.csv', last_sample_name, csv_line)\n",
    "\n",
    "#def writeLinesInCsv(file, last_sample_name, csv_line):\n",
    "#    with open(file, 'a') as fd:\n",
    "#        csv_line[1] = 'ISIC_00' + str(last_sample_name)\n",
    "#        fd.write(csv_line[0] + ',' + csv_line[1] + ',' + csv_line[2] + ',' + csv_line[3] + ',' + csv_line[4] + ',' + csv_line[5] + ',' + csv_line[6] +'\\n')\n",
    "\n",
    "#for image in images:\n",
    "        \n",
    "#    with open('HAM10000_metadata_with_more_samples.csv') as f_obj:\n",
    "#        reader = csv.reader(f_obj, delimiter=',')\n",
    "#        for line in reader:\n",
    "#            if image.split('/')[2].replace('.jpg', '') in line:  \n",
    "#                csv_line = line\n",
    "#                break\n",
    "    \n",
    "#    image_path = image.replace(image.split('/')[2], '') + 'ISIC_00' + str(last_sample_name) + '.jpg'\n",
    "#    flipImage(cv2.imread(image), image_path, 0, last_sample_name, csv_line) # Vertical\n",
    "#    last_sample_name += 1\n",
    "    \n",
    "#    image_path = image.replace(image.split('/')[2], '') + 'ISIC_00' + str(last_sample_name) + '.jpg'\n",
    "#    flipImage(cv2.imread(image), image_path, 1, last_sample_name, csv_line) # Horizontal\n",
    "#    last_sample_name += 1               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate a validation dataset in other folder moving 30% images. (Â¿BALANCEAR DATOS?)\n",
    "import random\n",
    "\n",
    "if os.path.exists('data_test'):\n",
    "    shutil.rmtree('data_test') \n",
    "\n",
    "os.mkdir('data_test')\n",
    "list = os.listdir('data_images/')\n",
    "for folder in list:\n",
    "    os.mkdir('data_test/' + folder)\n",
    "    folder_list = os.listdir('data_images/' + folder)\n",
    "    for to_copy in random.sample(folder_list, int(len(folder_list)*.3)):\n",
    "        shutil.move('data_images/' + folder + '/' + to_copy, 'data_test/' + folder + '/' + to_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7014 images belonging to 7 classes.\n",
      "Found 3001 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "train_data_dir = \"C:/Users/fiamm/Documents/Master_SIANI/CI/Cayetano/TrabajoFinal/data_images\"\n",
    "validation_data_dir = \"C:/Users/fiamm/Documents/Master_SIANI/CI/Cayetano/TrabajoFinal/data_test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=315,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(400, 400),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                    target_size=(400, 400),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "         activation='relu',\n",
    "         input_shape=(400,400,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss = tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer = tensorflow.keras.optimizers.Adadelta(),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "351/351 [==============================] - 1536s 4s/step - loss: 1.2553 - accuracy: 0.6458 - val_loss: 1.0691 - val_accuracy: 0.6701\n",
      "Epoch 2/200\n",
      "351/351 [==============================] - 1502s 4s/step - loss: 1.1141 - accuracy: 0.6654 - val_loss: 1.0259 - val_accuracy: 0.6701\n",
      "Epoch 3/200\n",
      "351/351 [==============================] - 1496s 4s/step - loss: 1.0309 - accuracy: 0.6813 - val_loss: 1.0071 - val_accuracy: 0.6701\n",
      "Epoch 4/200\n",
      "351/351 [==============================] - 1566s 4s/step - loss: 1.0594 - accuracy: 0.6741 - val_loss: 0.9957 - val_accuracy: 0.6701\n",
      "Epoch 5/200\n",
      "351/351 [==============================] - 1506s 4s/step - loss: 1.0414 - accuracy: 0.6717 - val_loss: 0.9894 - val_accuracy: 0.6701\n",
      "Epoch 6/200\n",
      "351/351 [==============================] - 1503s 4s/step - loss: 1.0206 - accuracy: 0.6719 - val_loss: 0.9809 - val_accuracy: 0.6701\n",
      "Epoch 7/200\n",
      "351/351 [==============================] - 1514s 4s/step - loss: 1.0165 - accuracy: 0.6676 - val_loss: 0.9824 - val_accuracy: 0.6701\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d7018d54c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', \n",
    "                   mode='max', \n",
    "                   verbose=1, \n",
    "                   patience=6, \n",
    "                   restore_best_weights=True)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    epochs = epochs,\n",
    "                    validation_data = validation_generator,\n",
    "                    callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelos/modeloIntento4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
